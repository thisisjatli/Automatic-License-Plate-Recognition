{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6124f23-ba9e-49ac-b5a3-99eeee2f57b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "# import import_ipynb\n",
    "%run model.ipynb import mymodel\n",
    "%run threshold.ipynb import IGTthreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb18993d-8aa3-4b1f-802c-02b733b14354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_t(img, pixel_cnt):\n",
    "#   boolidx = img<=1\n",
    "#   imgtmp = img[boolidx]\n",
    "#   # if imgtmp.shape[0] < pixel_cnt:\n",
    "#   #   thres = np.sum(imgtmp)/imgtmp.shape[0]\n",
    "#   # else:\n",
    "#   #   thres = np.sum(img)/pixel_cnt\n",
    "#   thres = np.sum(img)/pixel_cnt\n",
    "#   return thres\n",
    "\n",
    "# def frequency_grid(img, segment_length):\n",
    "#   w = img.shape[1]\n",
    "#   h = img.shape[0]\n",
    "#   rest_row = h%segment_length\n",
    "#   rest_col = w%segment_length\n",
    "#   segment_size = segment_length**2\n",
    "#   grid_size = (-1*(-w//segment_length), -1*(-h//segment_length))\n",
    "#   grid = np.zeros((grid_size[1], grid_size[0]))\n",
    "#   cur_row = 0\n",
    "#   cur_col = 0\n",
    "#   for i in range(grid_size[1]):\n",
    "#     for j in range(grid_size[0]):\n",
    "#       if i < grid_size[1]-1 and j < grid_size[0]-1:\n",
    "#         img_seg = img[cur_row:cur_row+segment_length, cur_col:cur_col+segment_length]\n",
    "#         grid[i, j] = (img_seg==0).sum()/segment_size\n",
    "#       elif i >= grid_size[1]-1 and j >= grid_size[0]-1:\n",
    "#         img_seg = img[cur_row:, cur_col:]\n",
    "#         if rest_row == 0 and rest_col == 0:\n",
    "#           grid[i, j] = (img_seg==0).sum()/segment_size\n",
    "#         elif rest_col == 0:\n",
    "#           grid[i, j] = (img_seg==0).sum()/(segment_length*rest_row)\n",
    "#         elif rest_row == 0:\n",
    "#           grid[i, j] = (img_seg==0).sum()/(segment_length*rest_col)\n",
    "#         else:\n",
    "#           grid[i, j] = (img_seg==0).sum()/(rest_col*rest_col)\n",
    "#       elif i >= grid_size[1]-1:\n",
    "#         img_seg = img[cur_row:, cur_col:segment_length]\n",
    "#         if rest_row == 0:\n",
    "#           grid[i, j] = (img_seg==0).sum()/segment_size\n",
    "#         else:\n",
    "#           grid[i, j] = (img_seg==0).sum()/(segment_length*rest_row)\n",
    "#       elif j >= grid_size[0]-1:\n",
    "#         img_seg = img[cur_row:segment_length, cur_col:]\n",
    "#         if rest_col == 0:\n",
    "#           grid[i, j] = (img_seg==0).sum()/segment_size\n",
    "#         else:\n",
    "#           grid[i, j] = (img_seg==0).sum()/(segment_length*rest_col)\n",
    "      \n",
    "#       cur_col += segment_length\n",
    "#     cur_row += segment_length\n",
    "#     cur_col = 0\n",
    "\n",
    "#   return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d6bb9c-d6b5-4a25-9e50-5d406cad787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def global_threshold(img):\n",
    "#   pixel_cnt = img.shape[0]*img.shape[1]\n",
    "#   img_equalized = img.copy()\n",
    "#   prev_thres = 0\n",
    "#   iter_cnt = 0\n",
    "#   while (iter_cnt < 10000):\n",
    "#     thres = calculate_t(img_equalized, pixel_cnt)\n",
    "#     # print('thres: ', thres)\n",
    "#     if prev_thres != 0 and abs(thres - prev_thres) < 0.0001:\n",
    "#       break\n",
    "#     img_subtracted = 1 - thres + img_equalized\n",
    "#     # ret, img_subtracted = cv2.threshold(img_subtracted, 1, 1, cv2.THRESH_TRUNC)\n",
    "#     e_min = np.amin(img_subtracted)\n",
    "#     img_equalized = 1 - ((1-img_subtracted) / (1-e_min))\n",
    "#     prev_thres = thres\n",
    "#     iter_cnt += 1\n",
    "#   # print(iter_cnt)\n",
    "#   # ret, img_equalized = cv2.threshold(img_equalized, 1, 1, cv2.THRESH_TRUNC)\n",
    "#   return img_equalized\n",
    "\n",
    "# def local_threshold(img_ori, seg_len, k):\n",
    "#   img = img_ori.copy()\n",
    "#   freq_grid = frequency_grid(img, seg_len)\n",
    "#   m = np.mean(freq_grid)\n",
    "#   s = np.std(freq_grid)\n",
    "#   grid_w = freq_grid.shape[1]\n",
    "#   grid_h = freq_grid.shape[0]\n",
    "#   cur_row = 0\n",
    "#   cur_col = 0\n",
    "#   for i in range(grid_h):\n",
    "#     for j in range(grid_w):\n",
    "#       if freq_grid[i, j] > m+k*s:\n",
    "#         if j < grid_w-1 and i < grid_h-1:\n",
    "#           img_seg = img[cur_row:cur_row+seg_len, cur_col:cur_col+seg_len]\n",
    "#           img[cur_row:cur_row+seg_len, cur_col:cur_col+seg_len] = global_threshold(img_seg)\n",
    "#         elif j >= grid_w-1 and i >= grid_h-1:\n",
    "#           img_seg = img[cur_row:, cur_col:]\n",
    "#           img[cur_row:, cur_col:] = global_threshold(img_seg)\n",
    "#         elif i >= grid_h-1:\n",
    "#           img_seg = img[cur_row:, cur_col:cur_col+seg_len]\n",
    "#           img[cur_row:, cur_col:cur_col+seg_len] = global_threshold(img_seg)\n",
    "#         elif j >= grid_w-1:\n",
    "#           img_seg = img[cur_row:cur_row+seg_len, cur_col:]\n",
    "#           img[cur_row:cur_row+seg_len:, cur_col:] = global_threshold(img_seg)\n",
    "\n",
    "#       cur_col += seg_len\n",
    "#     cur_row += seg_len\n",
    "#     cur_col = 0\n",
    "  \n",
    "#   return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa627d2-58cc-4ab2-9fc2-14407a4e2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def IGTthreshold(img):\n",
    "#     img_thres = global_threshold(img)\n",
    "#     seg_len = int(max(img.shape)/5)\n",
    "#     img_thres = local_threshold(img_thres, 50, 2)\n",
    "\n",
    "#     pix_cnt = img.shape[0]*img.shape[1]\n",
    "#     final_thres = calculate_t(img_thres, pix_cnt)\n",
    "\n",
    "#     return final_thres, img_thres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa53490b-8117-4dc1-bc40-7fcad0d57f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img_ori):\n",
    "    img = cv2.cvtColor(img_ori, cv2.COLOR_BGR2GRAY) # turn picture into grayscale\n",
    "    \n",
    "    img_w, img_h = img_ori.shape[1], img_ori.shape[0]\n",
    "    \n",
    "    img_rescale = img.copy()\n",
    "    img_rescale = img_rescale / 255\n",
    "    \n",
    "    thres, img_rescale = IGTthreshold(img_rescale)\n",
    "\n",
    "    ret, img_thres = cv2.threshold(img_rescale, thres, 255, cv2.THRESH_BINARY)\n",
    "    # ret, img_thres = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "    img = img_thres.astype('uint8')\n",
    "    # ret, img = cv2.threshold(img, 0.5*np.amax(img),255,cv2.THRESH_BINARY)\n",
    "\n",
    "    # img = cv2.erode(img, (5, 5))\n",
    "    # img = cv2.dilate(img, (5, 5))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f35a6c-1a5d-4736-8044-b849ac333c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with contours\n",
    "def get_charlist(img):\n",
    "    img_w, img_h = img.shape[1], img.shape[0] # width, height\n",
    "    img_copy = img.copy()\n",
    "    char_list = []\n",
    "    char_x = []\n",
    "\n",
    "    cntrs, _ = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # sort contours in descending order according to their areas\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    possible_w = 0 # possible width of a character\n",
    "    possible_h = 0 # possible height of a character\n",
    "    for cntr in cntrs:\n",
    "        x, y, w, h = cv2.boundingRect(cntr)\n",
    "        if w >= 0.25*img_w:\n",
    "            continue\n",
    "        else:\n",
    "            if possible_w == 0 and possible_h == 0:\n",
    "                possible_w = w\n",
    "                possible_h = h\n",
    "            if h >= 0.75*possible_h:\n",
    "                possible_w = (possible_w+w)/2\n",
    "                possible_h = (possible_h+h)/2\n",
    "\n",
    "                char_pic = img_copy[y:y+h, x:x+w]\n",
    "                char_list.append(char_pic)\n",
    "                char_x.append(x)\n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "    char_list = [c for _, c in sorted(zip(char_x, char_list))]\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b4e04-9870-48ba-b144-d199c2a36917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "modelpath = 'savedModel/mymodel_bs_256_e_200_lr_0.0001_wd_0.0001'\n",
    "device = get_device()\n",
    "model = mymodel().to(device)\n",
    "model.load_state_dict(torch.load(modelpath))\n",
    "\n",
    "# target index\n",
    "tfile = open('targets.pkl', 'rb')\n",
    "t = pickle.load(tfile)\n",
    "tfile.close()\n",
    "k_list = list(t.keys())\n",
    "l_list = list(t.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85837c74-81e3-44be-b4a1-cd3d48727b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_testdl(char_list):\n",
    "    x_test = []\n",
    "    trans = transforms.ToTensor()\n",
    "    for c in char_list:\n",
    "        c = cv2.resize(c, (64, 64))\n",
    "        x_test += [trans(c)]\n",
    "\n",
    "    test_dl = DataLoader(dataset=x_test, batch_size=1)\n",
    "    return test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e749c0fc-c4ff-4d89-ac66-4293dfbe6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e7ec8c6-43a3-45f5-beab-71da6e84f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(char_list):\n",
    "    result = ''\n",
    "    test_dl = get_testdl(char_list)\n",
    "    for x_test in test_dl:\n",
    "        x_test = x_test.to(device)\n",
    "        out = model(x_test)\n",
    "        y_pred = torch.argmax(out, axis=1)\n",
    "        y_label = k_list[l_list.index(y_pred)]\n",
    "        result += y_label\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdc9a583-006b-445c-bc42-2d997be427a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(img_ori):\n",
    "    # imgpath = 'test_sample.jpg'\n",
    "    # img_ori, img_plate = readimg(imgpath)\n",
    "    img_plate = process_img(img_ori)\n",
    "    char_list = get_charlist(img_plate)\n",
    "    result = predict(char_list)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0fef46a-9eef-469e-af61-00dbfb4bf80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVH466\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     img_ori = cv2.imread('car_demo/plate1002.png')\n",
    "#     result = output(img_ori)\n",
    "#     print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
